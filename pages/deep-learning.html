<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Deep Learning • Crosswalk Tutorial</title>
  <link rel="stylesheet" href="../assets/css/styles.css">
  <script defer src="../assets/js/nav.js"></script>
</head>
<body>
<header>
<nav class="nav wrapper">
  <a href="../index.html">Home</a>
  <a href="introduction.html">Introduction</a>
  <a href="challenges.html">Challenges</a>
  <a href="classical.html">Classical Methods</a>
  <a href="deep-learning.html">Deep Learning</a>
  <a href="multimodal.html">VLM / Multimodal</a>
  <a href="datasets.html">Datasets & Metrics</a>
  <a href="analysis.html">Comparative Analysis</a>
  <a href="future.html">Future</a>
  <a href="bibliography.html">Annotated Bibliography</a>
</nav>
</header>
<main class="wrapper">
  <h1>Deep Learning Approaches</h1>
  <p class="audio-note">Voice later: <code>assets/audio/deep-learning.mp3</code></p>
  <audio controls src="../assets/audio/deep-learning.mp3"></audio>
  <hr/>

  <p>
    Deep learning improved crosswalk detection by learning features directly from data instead of hand-crafting rules. A common setup trains <strong>object detectors</strong> (e.g., Faster R-CNN, YOLO) to localize crosswalk regions, or uses <strong>semantic segmentation</strong> networks (e.g., U-Net, DeepLab) to label pixels that belong to the crosswalk pattern. These models handle wear, mild occlusion, and viewpoint changes better than classical methods <a href="bibliography.html#ref-2">[2]</a><a href="bibliography.html#ref-7">[7]</a>.
  </p>

  <p>
    However, performance still depends on the diversity of the training data. Night scenes, heavy shadows, and new cities can cause drops due to <em>domain shift</em>. For deployment, researchers also report practical metrics such as <strong>FPS/latency</strong> and power, and explore model compression or edge-friendly variants for real-time use on devices like Jetson <a href="bibliography.html#ref-7">[7]</a>.
  </p>

  <figure style="margin-top:18px">
    <img src="../assets/images/crosswalk_placeholder2.png" alt="Detection and segmentation example" style="width:100%; border-radius:12px; border:1px solid #1f2a44">
    <figcaption>Two common pipelines: (left) object detection draws boxes; (right) segmentation labels crosswalk pixels (replace with your own figure + citation).</figcaption>
  </figure>

  <div class="card" style="margin-top:18px">
    <h3 style="margin-top:0">Typical Training Notes</h3>
    <ul>
      <li>Datasets: mix urban driving sets with task-specific crosswalk samples.</li>
      <li>Labels: bounding boxes (detection) or masks (segmentation).</li>
      <li>Metrics: mAP for detection; mIoU/pixel accuracy for segmentation.</li>
      <li>Robustness: augmentations for lighting, weather, and perspective.</li>
    </ul>
  </div>
</main>
<footer>
  <div class="wrapper">Last updated September 28, 2025 • Built for CS661 Project 1 • Author: Anas Niaz</div>
</footer>
</body>
</html>
